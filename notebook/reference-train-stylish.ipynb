{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference training notebook for Stylish TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "print(\"Downloading and extracting dataset...\")\n",
    "with io.capture_output():\n",
    "    !mkdir /content\n",
    "    %cd /content\n",
    "    !rm -r dataset\n",
    "    !mkdir dataset\n",
    "    !wget https://huggingface.co/datasets/hr16/ViVoicePP/resolve/main/CDMedia_processed.zip -nc\n",
    "    %cd dataset\n",
    "    !unzip ../CDMedia_processed.zip\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import sys\n",
    "from IPython.utils import io\n",
    "\n",
    "print(\"Installing k2-fsa...\")\n",
    "with io.capture_output():\n",
    "    py_version = f\"cp{sys.version_info.major}{sys.version_info.minor}\"\n",
    "    torch_ver, device = torch.__version__.split('+')\n",
    "    device = device[:len('cu12')] + '.' + device[len('cu12'):]\n",
    "    device = device.replace('cu', 'cuda')\n",
    "    base_url = \"https://k2-fsa.github.io/k2/installation/pre-compiled-cuda-wheels-linux/\"\n",
    "    index_page = BeautifulSoup(requests.get(base_url).text)\n",
    "    whl_url = None\n",
    "    for a_el in BeautifulSoup(requests.get(base_url + torch_ver).text).select('a.external'):\n",
    "        _whl_url = a_el.get('href')\n",
    "        if device in _whl_url and py_version in _whl_url:\n",
    "            whl_url = _whl_url\n",
    "            break\n",
    "    !pip install {whl_url}\n",
    "\n",
    "\n",
    "print(\"Installing Stylish...\")\n",
    "with io.capture_output():\n",
    "    %cd /content\n",
    "    !wget https://huggingface.co/Politrees/RVC_resources/resolve/main/predictors/rmvpe.pt -nc\n",
    "    !rm -r /content/stylish-dataset\n",
    "    !git clone https://github.com/Fannovel16/stylish-dataset/\n",
    "    \n",
    "    %cd /content\n",
    "    !rm -r stylish-tts\n",
    "    !git clone https://github.com/Fannovel16/stylish-tts/\n",
    "    %cd stylish-tts\n",
    "    try:\n",
    "        import munch\n",
    "    except:\n",
    "        !pip install matplotlib resampy -U\n",
    "        !pip install -r requirements.txt\n",
    "    %cd /content\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pitches using RMVPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /content/stylish-dataset\n",
    "print(\"Warmup may take a bit of time\")\n",
    "!python stylish-dataset/all-pitch.py \\\n",
    "    --method rmvpe \\\n",
    "    --rmvpe_checkpoint /content/rmvpe.pt \\\n",
    "    --wavdir /content/dataset \\\n",
    "    --trainpath /content/dataset/train_list.txt \\\n",
    "    --valpath /content/dataset/val_list.txt \\\n",
    "    --outpath /content/dataset/pitch.safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /content/stylish-tts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile config/model.yml\n",
    "multispeaker: false\n",
    "n_mels: 80\n",
    "sample_rate: 24000\n",
    "n_fft: 2048\n",
    "win_length: 1200\n",
    "hop_length: 300\n",
    "style_dim: 128\n",
    "inter_dim: 512\n",
    "\n",
    "text_aligner:\n",
    "  hidden_dim: 256\n",
    "  token_embedding_dim: 512\n",
    "\n",
    "decoder:\n",
    "  hidden_dim: 1024\n",
    "  residual_dim: 64\n",
    "\n",
    "generator:\n",
    "  type: 'ringformer'\n",
    "  resblock_kernel_sizes: [ 3, 7, 11 ]\n",
    "  upsample_rates: [ 4, 5 ]\n",
    "  upsample_initial_channel: 512\n",
    "  resblock_dilation_sizes: [ [ 1, 3, 5 ], [ 1, 3, 5 ], [ 1, 3, 5 ] ]\n",
    "  upsample_kernel_sizes: [ 8, 10 ]\n",
    "  gen_istft_n_fft: 60\n",
    "  gen_istft_hop_size: 15\n",
    "  depth: 2\n",
    "\n",
    "text_encoder:\n",
    "  tokens: 178 # number of phoneme tokens\n",
    "  hidden_dim: 192\n",
    "  filter_channels: 768\n",
    "  heads: 2\n",
    "  layers: 6\n",
    "  kernel_size: 3\n",
    "  dropout: 0.1\n",
    "\n",
    "style_encoder:\n",
    "  layers: 4\n",
    "\n",
    "duration_predictor:\n",
    "  n_layer: 3\n",
    "  max_dur: 50 # maximum duration of a single phoneme\n",
    "  dropout: 0.2\n",
    "\n",
    "pitch_energy_predictor:\n",
    "  dropout: 0.2\n",
    "\n",
    "# speech language model config\n",
    "slm:\n",
    "  model: 'microsoft/wavlm-base-plus'\n",
    "  sr: 16000 # sampling rate of SLM\n",
    "\n",
    "symbol:\n",
    "  pad: \"$\"\n",
    "  punctuation: \";:,.!?¡¿—…\\\"()“” \"\n",
    "  letters: \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "  letters_ipa: \"ɑɐɒæɓʙβɔɕçɗɖðʤəɘɚɛɜɝɞɟʄɡɠɢʛɦɧħɥʜɨɪʝɭɬɫɮʟɱɯɰŋɳɲɴøɵɸθœɶʘɹɺɾɻʀʁɽʂʃʈʧʉʊʋⱱʌɣɤʍχʎʏʑʐʒʔʡʕʢăǁᵊǃˈˌːˑʼʴʰʱʲʷˠˤ˞↓↑→↗↘'̩'ᵻ\"\n",
    "  voiced: \"ɑɐɒæɓʙβɔɗɖðʤəɘɚɛɜɝɞɟʄɡɠɢʛɦɥɨɪʝɭɫɮʟɱɯɰŋɳɲɴøɵœɶɹɺɾʀʁɽʉʊʋⱱʌɣɤʎʏʑʐʒʔʕʢᵊᵻˈˌ\"\n",
    "  unvoiced: \"ɕçɧħʜɬɸθʘɻʂʃʈʧʍχʡǀǁǃːˑʼʴʰʱʲʷˠˤ˞pftsckxqh↓↑→↗↘'̩';:,.!?¡¿—…\\\"()“” $\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile config/config.yml\n",
    "training:\n",
    "  # log training data every this number of steps\n",
    "  log_interval: 100\n",
    "  # validate and save model every this number of steps\n",
    "  save_interval: 2500\n",
    "  # validate model every this number of steps\n",
    "  val_interval: 2500\n",
    "  device: \"cuda\"\n",
    "  # Keep this as 'no' if you have the VRAM.\n",
    "  # Lower precision slows training.\n",
    "  # \"bf16\", \"fp16\", or \"no\" for no mixed precision\n",
    "  mixed_precision: \"no\"\n",
    "\n",
    "# Number of epochs, max batch sizes and general learning rate of each stage.\n",
    "training_plan:\n",
    "  alignment:\n",
    "    # alignment pretraining\n",
    "    epochs: 8\n",
    "    # Maximum number of segments per batch.\n",
    "    probe_batch_max: 128\n",
    "    # Learing Rate for this stage\n",
    "    lr: 3e-5\n",
    "  acoustic:\n",
    "    # training of acoustic models and vocoder\n",
    "    epochs: 10\n",
    "    probe_batch_max: 8\n",
    "    lr: 1e-4\n",
    "  textual:\n",
    "    # training for duration/pitch/energy from text\n",
    "    epochs: 20\n",
    "    probe_batch_max: 16\n",
    "    lr: 1e-4\n",
    "\n",
    "dataset:\n",
    "  train_data: \"/content/dataset/train_list.txt\"\n",
    "  val_data: \"/content/dataset/val_list.txt\"\n",
    "  wav_path: \"/content/dataset\"\n",
    "  pitch_path: \"/content/dataset/pitch.safetensors\"\n",
    "  alignment_path: \"/content/dataset/alignment.safetensors\"\n",
    "\n",
    "validation:\n",
    "  # Number of samples to generate per validation step\n",
    "  sample_count: 10\n",
    "  # Specific segments to use for validation\n",
    "  # force_samples:\n",
    "  # - \"filename.from.val_data.txt\"\n",
    "  # - \"other.filename.from.val_data.txt\"\n",
    "  # - \"other.other.filename.from.val_data.txt\"\n",
    "\n",
    "\n",
    "# Weights are pre-tuned. Do not change these unless you\n",
    "# know what you are doing.\n",
    "loss_weight:\n",
    "  # mel reconstruction loss\n",
    "  mel: 5\n",
    "  # generator loss\n",
    "  generator: 2\n",
    "  # speech-language model feature matching loss\n",
    "  slm: 0.2\n",
    "  # pitch F0 reconstruction loss\n",
    "  pitch: 3\n",
    "  # energy reconstruction loss\n",
    "  energy: 1\n",
    "  # duration loss\n",
    "  duration: 1\n",
    "  # duration predictor probability output cross entropy loss\n",
    "  duration_ce: 1\n",
    "  # style reconstruction loss\n",
    "  style: 1\n",
    "  # magnitude/phase loss\n",
    "  magphase: 1\n",
    "  # confidence for alignment (placeholder)\n",
    "  confidence: 1\n",
    "  # alignment loss\n",
    "  align_loss: 1\n",
    "  # discriminator loss (placeholder)\n",
    "  discriminator: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train alignment model TDNN_BLSTM-CTC and cache the alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=\"$PYTHONPATH:/content/stylish-tts/train:/content/stylish-tts/lib\" python \\\n",
    "    train/stylish_train/train.py \\\n",
    "    --model_config_path config/model.yml \\\n",
    "    --config_path config/config.yml \\\n",
    "    --stage alignment \\\n",
    "    --out_dir /content/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=\"$PYTHONPATH:/content/stylish-tts/train:/content/stylish-tts/lib\" python \\\n",
    "    train/stylish_train/dataprep/align_text.py \\\n",
    "    --model_config_path config/model.yml \\\n",
    "    --config_path config/config.yml \\\n",
    "    --model /content/checkpoints/alignment_model.safetensors \\\n",
    "    --out /content/dataset/alignment.safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out samples having misaligned phonemes by confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FILTER_PERCENTAGE = 0.2\n",
    "\n",
    "from pathlib import Path\n",
    "lines = Path(\"/content/dataset/scores_train.txt\").read_text().splitlines()\n",
    "data = []\n",
    "for line in lines:\n",
    "    score, path = line.split(' ', 1)\n",
    "    score = float(score)\n",
    "    data.append((path, score))\n",
    "data.sort(key=lambda x: x[1])\n",
    "threshold = data[:int(len(data) * FILTER_PERCENTAGE)][-1][1]\n",
    "threshold = round(threshold, 2)\n",
    "removed = set([path for path, score in data if score < threshold])\n",
    "\n",
    "filtered_lines = []\n",
    "for line in Path(\"/content/dataset/train_list.txt\").read_text(encoding=\"utf-8\").splitlines():\n",
    "    path, ipa, *others = line.split('|')\n",
    "    if path not in removed: filtered_lines.append(line)\n",
    "\n",
    "Path(\"/content/dataset/filtered_train_list.txt\").write_text('\\n'.join(filtered_lines), encoding=\"utf-8\")\n",
    "!sed -i 's/\\/train_list.txt/\\/filtered_train_list.txt/' config/config.yml\n",
    "print(f\"Filtered out {len(removed)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=\"$PYTHONPATH:/content/stylish-tts/train:/content/stylish-tts/lib\" python \\\n",
    "    train/stylish_train/train.py \\\n",
    "    --model_config_path config/model.yml \\\n",
    "    --config_path config/config.yml \\\n",
    "    --stage acoustic \\\n",
    "    --out_dir /content/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload checkpoints to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login --token=\"YOUR_HF_MODEL_TOKEN\"\n",
    "!huggingface-cli upload stylish-tts-cd-media /content/checkpoints/textual/ ."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
