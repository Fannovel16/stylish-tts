training:
  # log training data every this number of steps
  log_interval: 100
  # validate and save model every this number of steps
  save_interval: 5000
  # validate model every this number of steps
  val_interval: 5000
  device: "cuda"
  # Keep this as 'no' if you have the VRAM.
  # Lower precision slows training.
  # "bf16", "fp16", or "no" for no mixed precision
  mixed_precision: "no"
  # Maximum number of segments per batch.
  # Increasing this slows training overall even if
  # epochs go by faster.
  probe_batch_max: 2

# Number of epochs to train each stage. These numbers
# assume 25 hours of training data. Decrease them
# proportionately for larger datasets.
training_plan:
  pre_acoustic: 12
  acoustic: 24
  pre_textual: 12
  textual: 24
  joint: 24
  sbert: 12

# See README.md for specifications on the dataset and
# how to generate these files.
dataset:
  train_data: "path/to/your/train-list.txt"
  val_data: "path/to/your/val-list.txt"
  wav_path: "path/to/your/wav-files"
  pitch_path: "path/to/your/pitch.safetensors"

# Weights are pre-tuned. Do not change these unless you
# know what you are doing.
loss_weight:
  # mel reconstruction loss
  mel: 5
  # generator loss
  generator: 1
  # speech-language model feature matching loss
  slm: 1
  # monotonic alignment loss
  mono: 1
  # sequence-to-sequence loss
  s2s: 1
  # pitch F0 reconstruction loss
  pitch: 0.1
  # energy reconstruction loss
  energy: 1
  # duration loss
  duration: 1
  # duration predictor probability output cross entropy loss
  duration_ce: 20
  # style reconstruction loss
  style: 1
  # magnitude/phase loss
  magphase: 1

# Learning rates are pre-tuned. Do not change these unless
# you know what you are doing
optimizer:
  lr: 0.00002 # general learning rate
  bert_lr: 0.00001 # learning rate for PLBERT
  ft_lr: 0.00001 # learning rate for acoustic modules
